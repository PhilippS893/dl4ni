
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Classifying MNIST &#8212; DeepLearning for Neuroimaging</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Hyperparameter sweeps with Weights&amp;Biases" href="sweep_intro.html" />
    <link rel="prev" title="Introduction" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">DeepLearning for Neuroimaging</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    An introduction to DeepLearning for Neuroimaging
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Course Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../_part1/authors.html">
   Authors
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Prerequisites
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../prereqs/anns.html">
   What are Neural Nets?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="datasets.html">
   PyTorch datasets and dataloaders
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Using the toolbox
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Classifying MNIST
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="sweep_intro.html">
   Hyperparameter sweeps with Weights&amp;Biases
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lrp.html">
   Explainable AI
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/PhilippS893/dl4ni/master?urlpath=tree/docs/notebooks/classify_mnist.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/PhilippS893/dl4ni"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/PhilippS893/dl4ni/issues/new?title=Issue%20on%20page%20%2Fnotebooks/classify_mnist.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/notebooks/classify_mnist.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-and-inspect-the-mnist-data">
   Download and inspect the MNIST data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-a-simple-linear-neural-network">
   Creating a simple linear neural network
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-the-model-to-classify-hand-written-digits">
   Training the model to classify hand-written digits
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-the-training-procedure">
     Define the training procedure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-model-performance">
     Check model performance
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-a-ccn">
   Using a CCN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise">
   Exercise
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Classifying MNIST</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-and-inspect-the-mnist-data">
   Download and inspect the MNIST data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-a-simple-linear-neural-network">
   Creating a simple linear neural network
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-the-model-to-classify-hand-written-digits">
   Training the model to classify hand-written digits
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-the-training-procedure">
     Define the training procedure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-model-performance">
     Check model performance
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-a-ccn">
   Using a CCN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise">
   Exercise
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="classifying-mnist">
<h1>Classifying MNIST<a class="headerlink" href="#classifying-mnist" title="Permalink to this headline">#</a></h1>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">module_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;../../fmriDEEP&#39;</span><span class="p">))</span>
<span class="k">if</span> <span class="n">module_path</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="p">:</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p align="justify">We can now import the necessary packages and tools to train a simple linear classifier with PyTorch and my custom code.</p><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># other packages</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Subset</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># custom packages</span>
<span class="kn">from</span> <span class="nn">_core.utils.train_fns</span> <span class="kn">import</span> <span class="n">standard_train</span> <span class="c1"># this is a predefined training function we will use</span>
<span class="kn">from</span> <span class="nn">_core.utils.tools</span> <span class="kn">import</span> <span class="n">compute_accuracy</span>   <span class="c1"># a custom function to compute the accuracy scores</span>
<span class="kn">from</span> <span class="nn">_core.networks.LinearNets</span> <span class="kn">import</span> <span class="n">SimpleLinearModel</span>
<span class="kn">from</span> <span class="nn">_core.networks.ConvNets</span> <span class="kn">import</span> <span class="n">Simple2dCnnClassifier</span>

<span class="c1"># this variable contains information whether a GPU can be used for training. If not, we automatically use the CPU.</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p align="justify">To ensure reproducibility we set the random seed for all sorts of randomizer tools.</p><div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set the random seed for reproducibility</span>
<span class="k">def</span> <span class="nf">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">random</span> 
    
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span> <span class="c1"># can be used in pytorch dataloaders for reproducible sample selection when shuffle=True</span>
    <span class="n">g</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">g</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">set_random_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="download-and-inspect-the-mnist-data">
<h2>Download and inspect the MNIST data<a class="headerlink" href="#download-and-inspect-the-mnist-data" title="Permalink to this headline">#</a></h2>
<p>The easiest benchmark test for any neural network is to test its classification performance on the MNIST dataset.
This dataset contains thousands of hand-written digit exemplars.
As it is quite easy to use, we will employ it here as well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_train</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;./data/&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;./data/MNIST&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">())</span>
<span class="n">mnist_test</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;./data/&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Let us look at some examples from the dataset:</p>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mnist_train</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/classify_mnist_10_0.png" src="../_images/classify_mnist_10_0.png" />
</div>
</div>
<p align="justify">What you also always should do is look at your data or something that data scientists would call 'Exploratory Data Analysis' (EDA). EDA usually can be quite extensive and they are- for now -too much for the scope of this book. 
<p>We can now turn our attention to creating the network and setting up the training procedure.</p></p>
</section>
<section id="creating-a-simple-linear-neural-network">
<h2>Creating a simple linear neural network<a class="headerlink" href="#creating-a-simple-linear-neural-network" title="Permalink to this headline">#</a></h2>
<p align="justify">As demonstrated in the previous chapter, it is fairly easy to create a default linear network with the toolbox.</p><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For the simplest version of a linear neural network this is all you have to do:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleLinearModel</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># we print the model summary here again.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SimpleLinearModel                        [1, 10]                   --
├─Sequential: 1-1                        --                        10,336
│    └─Sequential: 2-1                   [1, 128]                  --
│    │    └─Linear: 3-1                  [1, 128]                  100,480
│    │    └─ReLU: 3-2                    [1, 128]                  --
├─Dropout: 1-2                           [1, 128]                  --
├─Sequential: 1-1                        --                        10,336
│    └─Sequential: 2-2                   [1, 64]                   --
│    │    └─Linear: 3-3                  [1, 64]                   8,256
│    │    └─ReLU: 3-4                    [1, 64]                   --
├─Dropout: 1-4                           [1, 64]                   --
├─Sequential: 1-1                        --                        10,336
│    └─Sequential: 2-3                   [1, 32]                   --
│    │    └─Linear: 3-5                  [1, 32]                   2,080
├─Dropout: 1-4                           [1, 64]                   --
├─Softmax: 1-5                           --                        --
├─Sequential: 1-1                        --                        10,336
│    └─Sequential: 2                     --                        --
│    │    └─ReLU: 3-6                    [1, 32]                   --
├─Linear: 1-6                            [1, 10]                   330
==========================================================================================
Total params: 111,146
Trainable params: 111,146
Non-trainable params: 0
Total mult-adds (M): 0.11
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.00
Params size (MB): 0.44
Estimated Total Size (MB): 0.45
==========================================================================================
</pre></div>
</div>
</div>
</div>
<p align="justify">Now that we know a little bit about the data and we defined our network it is now time to train the network.</p></section>
<section id="training-the-model-to-classify-hand-written-digits">
<h2>Training the model to classify hand-written digits<a class="headerlink" href="#training-the-model-to-classify-hand-written-digits" title="Permalink to this headline">#</a></h2>
<p>As the goal of the toolbox is to make it as easy as possible for you, the user, it comes with a predefined <code class="docutils literal notranslate"><span class="pre">standard_train</span></code> function. The code below (click the button to expand) shows you what this function looks like and, again, for ease of use, this function is being used by default when you create any model of the toolbox (e.g., <code class="docutils literal notranslate"><span class="pre">SimpleLinearModel</span></code>, <code class="docutils literal notranslate"><span class="pre">Simple2dCnnClassifier</span></code>, etc).</p>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the standard_train function</span>
<span class="c1"># it requires some additional packages that we import here</span>
<span class="c1"># in case you simply want to use it you do not have to worry about</span>
<span class="c1"># implementing these packages, the toolbox does this automatically for you.</span>
<span class="c1"># We just show it here for completeness</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">CrossEntropyLoss</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>


<span class="k">def</span> <span class="nf">standard_train</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">train_data</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="o">=</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">.00001</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
        <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">optimizer_kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A simple function to train a supplied neural network for multiclass problems.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: only necessary if this function is not supplied to the model constructor. Otherwise model.fit()</span>
<span class="sd">            calls the function with model=self</span>
<span class="sd">        train_data (DataLoader): dataloader used for training or validation/test if function is called in model.eval()</span>
<span class="sd">            context</span>
<span class="sd">        loss_fn: loss function to use (default: CrossEntropyLoss)</span>
<span class="sd">        optimizer: optimizer to use to adjust weights in backward pass (default: Adam)</span>
<span class="sd">        lr (float): the learning rate for the optimizer</span>
<span class="sd">        device (torch.device): do computations on device, e.g., cpu or gpu (default: cpu)</span>
<span class="sd">        train (bool): set the network into training mode (True|default) or evaluation (False)</span>
<span class="sd">        **optimizer_kwargs: additional arguments for the supplied optimizer</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[epoch_loss, stats]: the stats variable contains multiple values. The first 0:n_classes columns contains</span>
<span class="sd">        the classification probability for a given input (row). The second to last column (i.e., stats[:,-2]) contains</span>
<span class="sd">        the predicted label. The last column (i.e. stats[:, -1] contains the real label.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># set the model into training mode if it is not and train=True</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># here is something new: the optimizer</span>
    <span class="c1"># The optimizer determines the algorithm with which the weights of the layers</span>
    <span class="c1"># are adjusted. Here we use the &#39;Adam&#39; algorithm by default.</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="o">**</span><span class="n">optimizer_kwargs</span><span class="p">)</span>

    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># the batch loop. Within this loop we iterate over all samples stored in the</span>
    <span class="c1"># train_data variable.</span>
    <span class="c1"># the variable &#39;batch&#39; represents the current iteration [integer value]</span>
    <span class="c1"># the variable &#39;inputs&#39; is the actual input data in the shape of batch_size-by-inputshape</span>
    <span class="c1"># the variable &#39;labels&#39; contains the respective class label</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_data</span><span class="p">):</span>

        <span class="c1"># in this function we transfer the data and the label tensors to the chosen device</span>
        <span class="c1"># NOTE: I RECOMMEND TRANSFERING THE DATA AND LABELS TO THE DEVICE WHEN YOU LOAD THEM</span>
        <span class="c1"># MORE ON THIS IN A DIFFERENT STEP THOUGH [see DataSets and DataLoaders)</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># reset the gradients</span>
        <span class="c1"># a crucial step in training the networks. Otherwise the gradients accumulate after</span>
        <span class="c1"># each batch iteration and weird stuff will happen.</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>  <span class="c1"># forward pass through model</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>  <span class="c1"># calculate loss</span>

        <span class="c1"># in this statement we check if the network is currently in training mode,</span>
        <span class="c1"># which means, that every layer in the network has the required_grad flag set</span>
        <span class="c1"># to True. This in turn means that the backpropagation algorithm is executed.</span>
        <span class="c1"># If the model, however, is not in training mode we do not want to exectue</span>
        <span class="c1"># the backward pass and we also do not want to store the so-called pytorch graph.</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># do a backward pass</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># update parameters</span>

        <span class="c1"># get the probabilities of the predictions</span>
        <span class="n">prediction_probs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">SM</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="c1"># get the label number of the output</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># sum up the loss over all batches</span>

        <span class="c1"># just a helper variable</span>
        <span class="n">inter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">[</span><span class="n">prediction_probs</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
             <span class="n">labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[:,</span> <span class="kc">None</span><span class="p">],</span>
             <span class="n">predicted_labels</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[:,</span> <span class="kc">None</span><span class="p">]]</span>
        <span class="p">)</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">stats</span><span class="p">,</span> <span class="n">inter</span><span class="p">])</span> <span class="k">if</span> <span class="s1">&#39;stats&#39;</span> <span class="ow">in</span> <span class="nb">vars</span><span class="p">()</span> <span class="k">else</span> <span class="n">inter</span>  <span class="c1"># noqa</span>

    <span class="k">return</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span> <span class="n">stats</span>  <span class="c1"># noqa</span>
</pre></div>
</div>
</div>
</div>
<p>Okay. Now that we know a little bit about how our model is trained, we need to do some preparation work first.
That means we will download the MNIST dataset and then setup a training loop.</p>
<p>Let’s do that!</p>
<section id="define-the-training-procedure">
<h3>Define the training procedure<a class="headerlink" href="#define-the-training-procedure" title="Permalink to this headline">#</a></h3>
<p>We should first make sure that our network is also on our detected device. In case you do not send your model or your data to the same device you will run into errors.</p>
<p>Next, we should determine for how long, that is how many <em>epochs</em>, we want to train our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># first, we should make sure the network is on the correct device:</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">);</span>

<span class="c1"># define the number of epochs (that is training iterations) you want your model to go through</span>
<span class="c1"># let&#39;s say we want this to be 10 epochs</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Make sure you only send your model to a device <em>once</em>. If you have multiple lines of this <a class="reference external" href="http://model.to">model.to</a>(DEVICE) it can lead to unwanted results. I speak from experience</p>
</div>
<p>Now we setup the dataloaders for the training function. In case you have not gone through the tutorial on <a class="reference internal" href="datasets.html#dataloader-chapter"><span class="std std-ref">dataloader</span></a> I suggest you do this at some point to undestand what they are good for and how to define them.</p>
<p>The PyTorch community has a really good introduction on their <a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">offcial website</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the dataloaders</span>
<span class="n">dl_train</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">g</span><span class="p">)</span>
<span class="n">dl_test</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># start training the network</span>

<span class="c1"># set some variables here, such that we can create pretty plots</span>
<span class="n">train_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
<span class="n">test_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
<span class="n">train_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
<span class="n">test_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>

<span class="c1"># loop for the above set number of epochs</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">):</span>

    <span class="c1"># THIS IS WHERE THE MAGIC HAPPENS</span>
    <span class="c1"># calling the model.fit() function will execute the &#39;standard_train&#39; function as defined above.</span>
    <span class="n">train_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">train_stats</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dl_train</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">.001</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">train_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">train_stats</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">train_stats</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">2</span><span class="p">])</span>

    <span class="c1"># for validating or testing set the network into evaluation mode such that layers like dropout are not active</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">test_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">test_stats</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dl_test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">test_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">test_stats</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">test_stats</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">2</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;epoch=</span><span class="si">%03d</span><span class="s1">, train_loss=</span><span class="si">%1.3f</span><span class="s1">, train_acc=</span><span class="si">%1.3f</span><span class="s1">, test_loss=</span><span class="si">%1.3f</span><span class="s1">, test_acc=</span><span class="si">%1.3f</span><span class="s1">&#39;</span> <span class="o">%</span> 
         <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">train_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">test_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">test_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]))</span>

<span class="c1"># let&#39;s save the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_lin_mnist&#39;</span><span class="p">,</span> <span class="n">save_full</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=000, train_loss=0.959, train_acc=0.687, test_loss=0.337, test_acc=0.906
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=001, train_loss=0.428, train_acc=0.877, test_loss=0.238, test_acc=0.933
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=002, train_loss=0.336, train_acc=0.906, test_loss=0.198, test_acc=0.944
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=003, train_loss=0.292, train_acc=0.918, test_loss=0.156, test_acc=0.954
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=004, train_loss=0.260, train_acc=0.928, test_loss=0.144, test_acc=0.957
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=005, train_loss=0.235, train_acc=0.934, test_loss=0.135, test_acc=0.961
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=006, train_loss=0.220, train_acc=0.938, test_loss=0.125, test_acc=0.964
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=007, train_loss=0.211, train_acc=0.941, test_loss=0.122, test_acc=0.965
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=008, train_loss=0.202, train_acc=0.942, test_loss=0.116, test_acc=0.967
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=009, train_loss=0.193, train_acc=0.947, test_loss=0.110, test_acc=0.967
Saving entire model my_lin_mnist/model.pth
</pre></div>
</div>
</div>
</div>
<p>That was not so bad was it? Quite simple in fact, I hope. <br>
Please keep in mind that we try to incorporate the epoch loop into the model.fit() function as well. <br>For now, we unfortunately encounter some memory leaks that we first need to solve.</p>
</section>
<section id="check-model-performance">
<h3>Check model performance<a class="headerlink" href="#check-model-performance" title="Permalink to this headline">#</a></h3>
<p>Let’s look if our network really learned something. For that we will plot some loss and accuracy scores as a function of the epoch as well as a confusion matrix for the test data.</p>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">_core.utils.plots</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">train_loss</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">);</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;CrossEntropyLoss&#39;</span><span class="p">),</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">),</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">));</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">train_acc</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">test_acc</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">);</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">),</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">),</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="s2">&quot;chance&quot;</span><span class="p">));</span>

<span class="n">lin_conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test_stats</span><span class="p">[:,</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">test_stats</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/classify_mnist_30_0.png" src="../_images/classify_mnist_30_0.png" />
</div>
</div>
<p>This looks great! The line plots clearly indicate a downard trend in the loss curve (left) and an upward trend in the accuracy curve, respectively. Further, we can see that the test loss is lower than in the train. This is somewhat interesting as usually the training set performs better than the test or validation data. It is important to note that the loss and accuracy scores are averages for a given epoch. The training set is about 6 times larger than the test set in the case of MNIST. This is only one explanation of why we get curves like these.</p>
<p>Now, let me show you how easy it is to switch to another type of neural network: a convolutional neural network (CNN) model</p>
</section>
</section>
<section id="using-a-ccn">
<h2>Using a CCN<a class="headerlink" href="#using-a-ccn" title="Permalink to this headline">#</a></h2>
<p>Changing to a CNN with the toolbox is quite simple. Instead of the <code class="docutils literal notranslate"><span class="pre">SimpleLinearModel</span></code> we now use the <code class="docutils literal notranslate"><span class="pre">Simple2dCnnClassifier</span></code>.</p>
<p>As the name suggest we are now working with data that is 2-dimensional. Luckily for us the MNIST images are just that. We also know that the MNIST images have 28-by-28 pixels. Thus our input_dims for the model are now [28, 28]. The number of classes remains at 10.</p>
<p>We also again can use the <code class="docutils literal notranslate"><span class="pre">summary</span></code> function to better understand how the model is configured.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Images usually have color channels, thus the input of our images needs to be (batch, channels, pixeldim1, pixeldim2)</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we actually do exactly the same as for the linear model. </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Simple2dCnnClassifier</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Simple2dCnnClassifier                    [1, 10]                   --
├─ReLU: 1-1                              --                        --
├─Dropout: 1-5                           [1, 256]                  --
├─Sequential: 1-3                        --                        --
│    └─Sequential: 2-1                   [1, 8, 14, 14]            --
│    │    └─Conv2d: 3-1                  [1, 8, 28, 28]            208
│    │    └─ReLU: 3-2                    [1, 8, 28, 28]            --
│    │    └─MaxPool2d: 3-3               [1, 8, 14, 14]            --
│    └─Sequential: 2-2                   [1, 16, 7, 7]             --
│    │    └─Conv2d: 3-4                  [1, 16, 14, 14]           3,216
│    │    └─ReLU: 3-5                    [1, 16, 14, 14]           --
│    │    └─MaxPool2d: 3-6               [1, 16, 7, 7]             --
│    └─Sequential: 2-3                   [1, 32, 3, 3]             --
│    │    └─Conv2d: 3-7                  [1, 32, 7, 7]             12,832
│    │    └─ReLU: 3-8                    [1, 32, 7, 7]             --
│    │    └─MaxPool2d: 3-9               [1, 32, 3, 3]             --
├─Dropout: 1-4                           [1, 288]                  --
├─Sequential: 1                          --                        --
│    └─Sequential: 2-4                   [1, 256]                  --
│    │    └─Linear: 3-10                 [1, 256]                  73,984
│    │    └─ReLU: 3-11                   [1, 256]                  --
├─Dropout: 1-5                           [1, 256]                  --
├─Sequential: 1                          --                        --
│    └─Sequential: 2-5                   [1, 128]                  --
│    │    └─Linear: 3-12                 [1, 128]                  32,896
│    │    └─ReLU: 3-13                   [1, 128]                  --
├─Softmax: 1-6                           --                        --
├─Linear: 1-7                            [1, 10]                   1,290
==========================================================================================
Total params: 124,426
Trainable params: 124,426
Non-trainable params: 0
Total mult-adds (M): 1.53
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.09
Params size (MB): 0.50
Estimated Total Size (MB): 0.59
==========================================================================================
</pre></div>
</div>
</div>
</div>
<p>Alrighty. Make sure you send the model to the device. We can keep the number of epochs and the dataloader the same as for the <code class="docutils literal notranslate"><span class="pre">SimpleLinearModel</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># first, we should make sure the network is on the correct device:</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Ok! Time to train your first 2-D CNN!</p>
<p>Notice that the code below essentially is the same as it is for the linear model. The only thing that changed is some variable names such that we can compare them. But isn’t that great? If we find a nice way we turn the below code into a function and simply supply a model to it and it runs. No matter the network.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>I also changed the learning rate from .001 to .01. Interesting effects can happen if one decreases or increases the learning rate. It is quite common however, that for deeper CNNs larger learning rates work better.</p>
</div>
<p>Finding the best, or at least a good combination of parameters is what we cover in the <a class="reference internal" href="sweep_intro.html#using-sweeps"><span class="std std-ref">next chapter</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># start training the network</span>

<span class="c1"># set some variables here, such that we can create pretty plots</span>
<span class="n">cnn_train_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
<span class="n">cnn_test_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
<span class="n">cnn_train_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
<span class="n">cnn_test_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>

<span class="c1"># loop for the above set number of epochs</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">):</span>

    <span class="c1"># THIS IS WHERE THE MAGIC HAPPENS</span>
    <span class="c1"># calling the model.fit() function will execute the &#39;standard_train&#39; function as defined above.</span>
    <span class="n">cnn_train_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">cnn_train_stats</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dl_train</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">.01</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">cnn_train_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">cnn_train_stats</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">cnn_train_stats</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">2</span><span class="p">])</span>

    <span class="c1"># for validating or testing set the network into evaluation mode such that layers like dropout are not active</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">cnn_test_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">cnn_test_stats</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dl_test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">cnn_test_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">cnn_test_stats</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">cnn_test_stats</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">2</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;epoch=</span><span class="si">%03d</span><span class="s1">, train_loss=</span><span class="si">%1.3f</span><span class="s1">, train_acc=</span><span class="si">%1.3f</span><span class="s1">, test_loss=</span><span class="si">%1.3f</span><span class="s1">, test_acc=</span><span class="si">%1.3f</span><span class="s1">&#39;</span> <span class="o">%</span> 
         <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">cnn_train_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">cnn_train_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">cnn_test_loss</span><span class="p">[</span><span class="n">epoch</span><span class="p">],</span> <span class="n">cnn_test_acc</span><span class="p">[</span><span class="n">epoch</span><span class="p">]))</span>

<span class="c1"># Let&#39;s save the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_cnn_mnist&#39;</span><span class="p">,</span> <span class="n">save_full</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=000, train_loss=0.387, train_acc=0.875, test_loss=0.077, test_acc=0.977
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=001, train_loss=0.166, train_acc=0.955, test_loss=0.066, test_acc=0.984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=002, train_loss=0.153, train_acc=0.959, test_loss=0.083, test_acc=0.979
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=003, train_loss=0.150, train_acc=0.962, test_loss=0.064, test_acc=0.983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=004, train_loss=0.150, train_acc=0.963, test_loss=0.070, test_acc=0.983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=005, train_loss=0.153, train_acc=0.962, test_loss=0.063, test_acc=0.984
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=006, train_loss=0.156, train_acc=0.961, test_loss=0.064, test_acc=0.983
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=007, train_loss=0.156, train_acc=0.963, test_loss=0.068, test_acc=0.985
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=008, train_loss=0.175, train_acc=0.959, test_loss=0.082, test_acc=0.981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>epoch=009, train_loss=0.178, train_acc=0.958, test_loss=0.059, test_acc=0.984
Saving entire model my_cnn_mnist/model.pth
</pre></div>
</div>
</div>
</div>
<p>Very nice. Let us see how the CNN performes compared to the linear network!</p>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">_core.utils.plots</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">train_loss</span><span class="p">,</span> 
             <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">cnn_train_loss</span><span class="p">,</span>
             <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">cnn_test_loss</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">);</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;CrossEntropyLoss&#39;</span><span class="p">),</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">),</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="s2">&quot;lintrain&quot;</span><span class="p">,</span> <span class="s2">&quot;lintest&quot;</span><span class="p">,</span> <span class="s2">&quot;cnntrain&quot;</span><span class="p">,</span> <span class="s2">&quot;cnntest&quot;</span><span class="p">));</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">train_acc</span><span class="p">,</span> 
             <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">test_acc</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">cnn_train_acc</span><span class="p">,</span>
             <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">cnn_test_acc</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">);</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">),</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">),</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="s2">&quot;lintrain&quot;</span><span class="p">,</span> <span class="s2">&quot;lintest&quot;</span><span class="p">,</span> <span class="s2">&quot;cnntrain&quot;</span><span class="p">,</span> <span class="s2">&quot;cnntest&quot;</span><span class="p">,</span> <span class="s2">&quot;chance&quot;</span><span class="p">));</span>

<span class="n">cnn_conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">cnn_test_stats</span><span class="p">[:,</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">cnn_test_stats</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/classify_mnist_40_0.png" src="../_images/classify_mnist_40_0.png" />
</div>
</div>
<p align="justify">It seems that the default CNN outperforms the default linear network. Pretty cool. However, we can also see that at about epoch 9 the train loss for the CNN seems to increase again. This might already indicate some overfitting issues. Something to bear in mind! 
<p>The graph below shows the difference of the CNN confusion matrix minus the LN confusion matrix. We can immediately see that the CNN outperforms the LN because the diagonal clearly has positive values in the majority of the classes. Remember: the diagonal means that the network correctly predicts the real class.</p></p>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cnn_conf_mat</span><span class="o">-</span><span class="n">lin_conf_mat</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;seismic&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Diff CNN_conf - Lin_conf&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/classify_mnist_42_0.png" src="../_images/classify_mnist_42_0.png" />
</div>
</div>
</section>
<section id="exercise">
<h2>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Try using the default (or your own configuration) of the <code class="docutils literal notranslate"><span class="pre">SimpleLinearModel</span></code> and the <code class="docutils literal notranslate"><span class="pre">Simple2dCnnClassifier</span></code> on the Fashion-MNIST dataset. See which performs better!</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="sweep_intro.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Hyperparameter sweeps with Weights&amp;Biases</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Philipp Seidel - Biomedical Imaging Dept. Uni Regensburg<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>